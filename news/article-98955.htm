<!doctype html>
<html xml:lang="zh-CN" lang="zh-CN">

<head>
        <link rel="canonical" href="https://clashnode.github.io/news/article-98955.htm" />
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
    <title>pytorch 自动构建任意层的深度神经网络(DNN)</title>
    <link rel="icon" href="/assets/website/img/clashnode/favicon.ico" type="image/x-icon"/>
        <meta name="description" content="动手撸神经网络的代码，是大家常常遇到的问题。在设计自己的网络时，需要考虑网络大小，隐藏层层数，激活函数和参数初始化方法。最笨拙的方法就是固定下来，发生变化就要手动调整一次。这里介绍一种可以自动生生网络" />
    
    <meta name="author" content="Clash Node官网订阅站">
    <meta property="og:type" content="article" />
    <meta property="og:url" content="https://clashnode.github.io/news/article-98955.htm" />
    <meta property="og:site_name" content="Clash Node官网订阅站" />
    <meta property="og:title" content="pytorch 自动构建任意层的深度神经网络(DNN)" />
    <meta property="og:image" content="https://clashnode.github.io/uploads/20240214/d407d00f6f64c9e8c53ebfcd676b4e55.webp" />
        <meta property="og:release_date" content="2025-04-19T08:55:45" />
    <meta property="og:updated_time" content="2025-04-19T08:55:45" />
        <meta property="og:description" content="动手撸神经网络的代码，是大家常常遇到的问题。在设计自己的网络时，需要考虑网络大小，隐藏层层数，激活函数和参数初始化方法。最笨拙的方法就是固定下来，发生变化就要手动调整一次。这里介绍一种可以自动生生网络" />
        
    <meta name="applicable-device" content="pc,mobile" />
    <meta name="renderer" content="webkit" />
    <meta name="force-rendering" content="webkit" />
    <meta http-equiv="Cache-Control" content="no-transform" />
    <meta name="robots" content="max-image-preview:large" />
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="apple-mobile-web-app-title" content="pytorch 自动构建任意层的深度神经网络(DNN)">
    <meta name="format-detection" content="telephone=no">

    <link rel="dns-prefetch" href="https:/www.googletagmanager.com">
    <link rel="dns-prefetch" href="https://www.googleadservices.com">
    <link rel="dns-prefetch" href="https://www.google-analytics.com">
    <link rel="dns-prefetch" href="https://pagead2.googlesyndication.com">
    <link rel="dns-prefetch" href="https://cm.g.doubleclick.net">
    <link rel="dns-prefetch" href="https://fonts.googleapis.com">

    <link href="https://fonts.googleapis.com/css2?family=Jost:wght@300;400;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="/assets/website/css/clashnode/style-starter.css">
    <!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-8B9V1K3BBT"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-8B9V1K3BBT');
</script>
    <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3332997411212854"
     crossorigin="anonymous"></script>
</head>

<body data-page="detail">
        <!-- header -->
    <header id="site-header" class="fixed-top">
        <div class="container">
            <nav class="navbar navbar-expand-lg stroke">
                <a class="navbar-brand" href="/">
                                        <span class="fa fa-laptop"></span> Clash Node                </a>
                <button class="navbar-toggler  collapsed bg-gradient" type="button" data-toggle="collapse" data-target="#navbarTogglerDemo02" aria-controls="navbarTogglerDemo02" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon fa icon-expand fa-bars"></span>
                    <span class="navbar-toggler-icon fa icon-close fa-times"></span>
                    </span>
                </button>
                <div class="collapse navbar-collapse" id="navbarTogglerDemo02">
                    <ul class="navbar-nav ml-auto">
                                                <li class="nav-item">
                            <a class="nav-link" href="/">首页</a>
                        </li>
                                                <li class="nav-item">
                            <a class="nav-link" href="/free-nodes/">免费节点</a>
                        </li>
                                                <li class="nav-item">
                            <a class="nav-link" href="/paid-subscribe/">推荐机场</a>
                        </li>
                                                <li class="nav-item">
                            <a class="nav-link" href="/client.htm">客户端</a>
                        </li>
                                                <li class="nav-item">
                            <a class="nav-link" href="/news/">新闻资讯</a>
                        </li>
                                            </ul>
                </div>
                <!-- toggle switch for light and dark theme -->
                <div class="mobile-position">
                    <nav class="navigation">
                        <div class="theme-switch-wrapper">
                            <label class="theme-switch" for="checkbox">
                                <input type="checkbox" id="checkbox">
                                <div class="mode-container">
                                    <i class="gg-sun"></i>
                                    <i class="gg-moon"></i>
                                </div>
                            </label>
                        </div>
                    </nav>
                </div>
                <!-- //toggle switch for light and dark theme -->
            </nav>
        </div>
    </header>
    <!-- //header -->
    <!-- about breadcrumb -->
    <section class="w3l-about-breadcrumb text-center">
        <div class="breadcrumb-bg breadcrumb-bg-about py-sm-5 py-4">
            <div class="container py-2">
                <h1 class="title" style="word-break: break-all;">pytorch 自动构建任意层的深度神经网络(DNN)</h1>
                <ul class="breadcrumbs-custom-path mt-2">
                    <li><a href="/">首页</a></li>
                    <li><span class="fa fa-arrow-right mx-2" aria-hidden="true"></span></li>
                    <li><a href="/news/">新闻资讯</a></li>
                    <li class="active"><span class="fa fa-arrow-right mx-2" aria-hidden="true"></span> 正文</li>
                </ul>
            </div>
        </div>
    </section>
    <!-- //about breadcrumb -->
    <div class="container py-lg-5 py-3">
        <div class="row">
            <div class="col-md-8">
                                <input type="hidden" id="share-website-info" data-name="" data-url="">
                  				  				  				<div id="content_views" class="markdown_views prism-dracula"> <p>动手撸神经网络的代码，是大家常常遇到的问题。在设计自己的网络时，需要考虑网络大小，隐藏层层数，激活函数和参数初始化方法。最笨拙的方法就是固定下来，发生变化就要手动调整一次。这里介绍一种可以自动生生网络的方法，每次改变只需要调整一些参数，网络就会自动改变，大大提升了生产代码的效率。<br /> 参考链接：<br /> 1、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/qq_37385726/article/details/81740233"  rel="nofollow">Pytorch之搭建神经网络的四种方法</a><br /> 2、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/bigkaimyc/article/details/103939696"  rel="nofollow">Pytorch–1.使用Pytorch搭建一个简易的神经网络</a><br /> 3、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/zkk9527/article/details/88399176"  rel="nofollow">十分钟掌握Pytorch搭建神经网络的流程</a><br /> 4、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/jining11/article/details/88728052"  rel="nofollow">使用pytorch搭建神经网络</a><br /> 5、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/weixin_42263486/article/details/108279905"  rel="nofollow">PyTorch使用教程-PyTorch构建神经网络(下)</a><br /> 6、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://blog.csdn.net/luo3300612/article/details/97675312"  rel="nofollow">Pytorch 默认参数初始化</a><br /> 7、<a href="http://www.m6000.cn/wp-content/themes/begin%20lts/inc/go.php?url=https://www.jianshu.com/p/1a1339c4acd7"  rel="nofollow">Pytorch中常用的四种优化器SGD、Momentum、RMSProp、Adam</a></p> <pre><code class="prism language-python"><span class="token comment"># -*- coding: utf-8 -*-</span> <span class="token triple-quoted-string string">""" Created on 2021.06.18 @author: LXA """</span> <span class="token keyword">import</span> torch <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> tn <span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> tnf <span class="token keyword">from</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>parameter <span class="token keyword">import</span> Parameter <span class="token keyword">import</span> numpy <span class="token keyword">as</span> np  <span class="token keyword">class</span> <span class="token class-name">my_actFunc</span><span class="token punctuation">(</span>tn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> actName<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token builtin">super</span><span class="token punctuation">(</span>my_actFunc<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>actName <span class="token operator">=</span> actName      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_input<span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token keyword">if</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'relu'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> tnf<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'leaky_relu'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> tnf<span class="token punctuation">.</span>leaky_relu<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'tanh'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>tanh<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'srelu'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> tnf<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span><span class="token operator">*</span>tnf<span class="token punctuation">.</span>relu<span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'elu'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> tnf<span class="token punctuation">.</span>elu<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'sin'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">elif</span> <span class="token builtin">str</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span>self<span class="token punctuation">.</span>actName<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token string">'sigmoid'</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> tnf<span class="token punctuation">.</span>sigmoid<span class="token punctuation">(</span>x_input<span class="token punctuation">)</span>         <span class="token keyword">else</span><span class="token punctuation">:</span>             out_x <span class="token operator">=</span> x_input         <span class="token keyword">return</span> out_x          <span class="token comment"># ----------------dense net(constructing NN and initializing weights and bias )------------</span> <span class="token keyword">class</span> <span class="token class-name">Pure_DenseNet</span><span class="token punctuation">(</span>tn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token triple-quoted-string string">"""     Args:         indim: the dimension for input data         outdim: the dimension for output         hidden_units: the number of  units for hidden layer, a list or a tuple         name2Model: the name of using DNN type, DNN , ScaleDNN or FourierDNN         actName2in: the name of activation function for input layer         actName: the name of activation function for hidden layer         actName2out: the name of activation function for output layer         scope2W: the namespace of weight         scope2B: the namespace of bias     """</span>     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> indim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> outdim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> hidden_units<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> name2Model<span class="token operator">=</span><span class="token string">'DNN'</span><span class="token punctuation">,</span> actName2in<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span> actName<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span>                  actName2out<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> scope2W<span class="token operator">=</span><span class="token string">'Weight'</span><span class="token punctuation">,</span> scope2B<span class="token operator">=</span><span class="token string">'Bias'</span><span class="token punctuation">,</span> type2float<span class="token operator">=</span><span class="token string">'float32'</span><span class="token punctuation">,</span> to_gpu<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> gpu_no<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token builtin">super</span><span class="token punctuation">(</span>Pure_DenseNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>indim <span class="token operator">=</span> indim         self<span class="token punctuation">.</span>outdim <span class="token operator">=</span> outdim         self<span class="token punctuation">.</span>hidden_units <span class="token operator">=</span> hidden_units         self<span class="token punctuation">.</span>name2Model <span class="token operator">=</span> name2Model         self<span class="token punctuation">.</span>actFunc_in <span class="token operator">=</span> my_actFunc<span class="token punctuation">(</span>actName<span class="token operator">=</span>actName2in<span class="token punctuation">)</span>         self<span class="token punctuation">.</span>actFunc <span class="token operator">=</span> my_actFunc<span class="token punctuation">(</span>actName<span class="token operator">=</span>actName<span class="token punctuation">)</span>         self<span class="token punctuation">.</span>actFunc_out <span class="token operator">=</span> my_actFunc<span class="token punctuation">(</span>actName<span class="token operator">=</span>actName2out<span class="token punctuation">)</span>         self<span class="token punctuation">.</span>dense_layers <span class="token operator">=</span> tn<span class="token punctuation">.</span>ModuleList<span class="token punctuation">(</span><span class="token punctuation">)</span>          input_layer <span class="token operator">=</span> tn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>indim<span class="token punctuation">,</span> out_features<span class="token operator">=</span>hidden_units<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>         tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>input_layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>         tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>uniform_<span class="token punctuation">(</span>input_layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>input_layer<span class="token punctuation">)</span>          <span class="token keyword">for</span> i_layer <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>hidden_units<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>             hidden_layer <span class="token operator">=</span> tn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>hidden_units<span class="token punctuation">[</span>i_layer<span class="token punctuation">]</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>hidden_units<span class="token punctuation">[</span>i_layer<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>             tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>             tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>uniform_<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>             self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>hidden_layer<span class="token punctuation">)</span>          out_layer <span class="token operator">=</span> tn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token operator">=</span>hidden_units<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> out_features<span class="token operator">=</span>outdim<span class="token punctuation">)</span>         tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>xavier_normal_<span class="token punctuation">(</span>out_layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span>         tn<span class="token punctuation">.</span>init<span class="token punctuation">.</span>uniform_<span class="token punctuation">(</span>out_layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>out_layer<span class="token punctuation">)</span>      <span class="token keyword">def</span> <span class="token function">get_regular_sum2WB</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> regular_model<span class="token operator">=</span><span class="token string">'L2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         regular_w <span class="token operator">=</span> <span class="token number">0</span>         regular_b <span class="token operator">=</span> <span class="token number">0</span>         <span class="token keyword">if</span> regular_model <span class="token operator">==</span> <span class="token string">'L1'</span><span class="token punctuation">:</span>             <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">:</span>                 regular_w <span class="token operator">=</span> regular_w <span class="token operator">+</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span>                 regular_b <span class="token operator">=</span> regular_b <span class="token operator">+</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">)</span><span class="token punctuation">)</span>         <span class="token keyword">elif</span> regular_model <span class="token operator">==</span> <span class="token string">'L2'</span><span class="token punctuation">:</span>             <span class="token keyword">for</span> layer <span class="token keyword">in</span> self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">:</span>                 regular_w <span class="token operator">=</span> regular_w <span class="token operator">+</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> layer<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span>                 regular_b <span class="token operator">=</span> regular_b <span class="token operator">+</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>layer<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> layer<span class="token punctuation">.</span>bias<span class="token punctuation">)</span><span class="token punctuation">)</span>         <span class="token keyword">return</span> regular_w<span class="token punctuation">,</span> regular_b      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">,</span> scale<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> training<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> mask<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token comment"># ------ dealing with the input data ---------------</span>         dense_in <span class="token operator">=</span> self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>         H <span class="token operator">=</span> dense_in<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>         H <span class="token operator">=</span> self<span class="token punctuation">.</span>actFunc_in<span class="token punctuation">(</span>H<span class="token punctuation">)</span>          <span class="token comment">#  ---resnet(one-step skip connection for two consecutive layers if have equal neurons）---</span>         hidden_record <span class="token operator">=</span> self<span class="token punctuation">.</span>hidden_units<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>         <span class="token keyword">for</span> i_layer <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>hidden_units<span class="token punctuation">)</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>             H_pre <span class="token operator">=</span> H             dense_layer <span class="token operator">=</span> self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">[</span>i_layer<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">]</span>             H <span class="token operator">=</span> dense_layer<span class="token punctuation">(</span>H<span class="token punctuation">)</span>             H <span class="token operator">=</span> self<span class="token punctuation">.</span>actFunc<span class="token punctuation">(</span>H<span class="token punctuation">)</span>             <span class="token keyword">if</span> self<span class="token punctuation">.</span>hidden_units<span class="token punctuation">[</span>i_layer <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">==</span> hidden_record<span class="token punctuation">:</span>                 H <span class="token operator">=</span> H <span class="token operator">+</span> H_pre             hidden_record <span class="token operator">=</span> self<span class="token punctuation">.</span>hidden_units<span class="token punctuation">[</span>i_layer <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">]</span>          dense_out <span class="token operator">=</span> self<span class="token punctuation">.</span>dense_layers<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span>         H <span class="token operator">=</span> dense_out<span class="token punctuation">(</span>H<span class="token punctuation">)</span>         H <span class="token operator">=</span> self<span class="token punctuation">.</span>actFunc_out<span class="token punctuation">(</span>H<span class="token punctuation">)</span>         <span class="token keyword">return</span> H   <span class="token keyword">class</span> <span class="token class-name">DNN_test</span><span class="token punctuation">(</span>tn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>     <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> dim_in<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> dim_out<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> hidden_layers<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> name2Model<span class="token operator">=</span><span class="token string">'DNN'</span><span class="token punctuation">,</span> actName_in<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span>                  actName_hidden<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span> actName_out<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> use_gpu<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> no2gpu<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token builtin">super</span><span class="token punctuation">(</span>DNN_test<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>         self<span class="token punctuation">.</span>name2Model <span class="token operator">=</span> name2Model         self<span class="token punctuation">.</span>dim_in <span class="token operator">=</span> dim_in         self<span class="token punctuation">.</span>dim_out <span class="token operator">=</span> dim_out         <span class="token keyword">if</span> name2Model <span class="token operator">==</span> <span class="token string">'DNN'</span><span class="token punctuation">:</span>             self<span class="token punctuation">.</span>DNN <span class="token operator">=</span> Pure_DenseNet<span class="token punctuation">(</span>indim<span class="token operator">=</span>dim_in<span class="token punctuation">,</span> outdim<span class="token operator">=</span>dim_out<span class="token punctuation">,</span> hidden_units<span class="token operator">=</span>hidden_layers<span class="token punctuation">,</span> name2Model<span class="token operator">=</span>name2Model<span class="token punctuation">,</span>                                      actName2in<span class="token operator">=</span>actName_in<span class="token punctuation">,</span> actName<span class="token operator">=</span>actName_hidden<span class="token punctuation">,</span> actName2out<span class="token operator">=</span>actName_out<span class="token punctuation">)</span>      <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_input<span class="token punctuation">,</span> freq<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         out <span class="token operator">=</span> self<span class="token punctuation">.</span>DNN<span class="token punctuation">(</span>x_input<span class="token punctuation">,</span> scale<span class="token operator">=</span>freq<span class="token punctuation">)</span>         <span class="token keyword">return</span> out      <span class="token keyword">def</span> <span class="token function">get_sum2wB</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>         <span class="token keyword">if</span> self<span class="token punctuation">.</span>name2Model <span class="token operator">==</span> <span class="token string">'DNN'</span> <span class="token keyword">or</span> self<span class="token punctuation">.</span>name2Model <span class="token operator">==</span> <span class="token string">'Scale_DNN'</span> <span class="token keyword">or</span> self<span class="token punctuation">.</span>name2Model <span class="token operator">==</span> <span class="token string">'Fourier_DNN'</span><span class="token punctuation">:</span>             sum2WB <span class="token operator">=</span> self<span class="token punctuation">.</span>DNN<span class="token punctuation">.</span>get_regular_sum2WB<span class="token punctuation">(</span><span class="token punctuation">)</span>         <span class="token keyword">return</span> sum2WB      <span class="token keyword">def</span> <span class="token function">cal_l2loss</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x_input<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> freq<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> y_input<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>         out <span class="token operator">=</span> self<span class="token punctuation">.</span>DNN<span class="token punctuation">(</span>x_input<span class="token punctuation">,</span> scale<span class="token operator">=</span>freq<span class="token punctuation">)</span>         squre_loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mul<span class="token punctuation">(</span>y_input <span class="token operator">-</span> out<span class="token punctuation">,</span> y_input <span class="token operator">-</span> out<span class="token punctuation">)</span>         loss <span class="token operator">=</span> torch<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>squre_loss<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>         <span class="token keyword">return</span> loss<span class="token punctuation">,</span> out   <span class="token keyword">def</span> <span class="token function">test_DNN</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>     batch_size <span class="token operator">=</span> <span class="token number">10</span>     dim_in <span class="token operator">=</span> <span class="token number">2</span>     dim_out <span class="token operator">=</span> <span class="token number">1</span>     hidden_list <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>     freq <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>     model_name <span class="token operator">=</span> <span class="token string">'DNN'</span>     init_lr <span class="token operator">=</span> <span class="token number">0.01</span>     max_it <span class="token operator">=</span> <span class="token number">10000</span>     with_gpu <span class="token operator">=</span> <span class="token boolean">True</span>      model <span class="token operator">=</span> DNN_test<span class="token punctuation">(</span>dim_in<span class="token operator">=</span>dim_in<span class="token punctuation">,</span> dim_out<span class="token operator">=</span>dim_out<span class="token punctuation">,</span> hidden_layers<span class="token operator">=</span>hidden_list<span class="token punctuation">,</span> name2Model<span class="token operator">=</span>model_name<span class="token punctuation">,</span> actName_in<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span>                 actName_hidden<span class="token operator">=</span><span class="token string">'tanh'</span><span class="token punctuation">,</span> use_gpu<span class="token operator">=</span>with_gpu<span class="token punctuation">,</span> no2gpu<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>     <span class="token keyword">if</span> with_gpu<span class="token punctuation">:</span>         model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda:'</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>      params2Net <span class="token operator">=</span> model<span class="token punctuation">.</span>DNN<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># 定义优化方法，并给定初始学习率</span>     <span class="token comment"># optimizer = torch.optim.SGD(params2Net, lr=init_lr)                     # SGD</span>     <span class="token comment"># optimizer = torch.optim.SGD(params2Net, lr=init_lr, momentum=0.8)       # momentum</span>     <span class="token comment"># optimizer = torch.optim.RMSprop(params2Net, lr=init_lr, alpha=0.95)     # RMSProp</span>     optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>params2Net<span class="token punctuation">,</span> lr<span class="token operator">=</span>init_lr<span class="token punctuation">)</span>  <span class="token comment"># Adam</span>      <span class="token comment"># 定义更新学习率的方法</span>     <span class="token comment"># scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.99)</span>     <span class="token comment"># scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 1/(epoch+1))</span>     scheduler <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.995</span><span class="token punctuation">)</span>     arr2epoch <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>     arr2loss <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>     arr2lr <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>     <span class="token keyword">for</span> i_epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>max_it<span class="token punctuation">)</span><span class="token punctuation">:</span>         x <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> dim_in<span class="token punctuation">)</span>         x <span class="token operator">=</span> x<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>         torch_x <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>x<span class="token punctuation">)</span>         y <span class="token operator">=</span> np<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sin<span class="token punctuation">(</span>x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">*</span> x<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> newshape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>         torch_y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>y<span class="token punctuation">)</span>         <span class="token keyword">if</span> with_gpu<span class="token punctuation">:</span>             torch_x <span class="token operator">=</span> torch_x<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda:'</span><span class="token operator">+</span><span class="token builtin">str</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>             torch_y <span class="token operator">=</span> torch_y<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>device<span class="token operator">=</span><span class="token string">'cuda:'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>          loss<span class="token punctuation">,</span> prediction <span class="token operator">=</span> model<span class="token punctuation">.</span>cal_l2loss<span class="token punctuation">(</span>x_input<span class="token operator">=</span>torch_x<span class="token punctuation">,</span> freq<span class="token operator">=</span>freq<span class="token punctuation">,</span> y_input<span class="token operator">=</span>torch_y<span class="token punctuation">)</span>         sum2wb <span class="token operator">=</span> model<span class="token punctuation">.</span>get_sum2wB<span class="token punctuation">(</span><span class="token punctuation">)</span>          optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 求导前先清零, 只要在下一次求导前清零即可</span>         loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 求偏导</span>         optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 更新参数</span>         scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>          <span class="token keyword">if</span> i_epoch <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>             <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'i_epoch --- loss:'</span><span class="token punctuation">,</span> i_epoch<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>             <span class="token comment"># print("第%d个epoch的学习率：%f" % (i_epoch, optimizer.param_groups[0]['lr']))</span>             arr2loss<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>             arr2lr<span class="token punctuation">.</span>append<span class="token punctuation">(</span>optimizer<span class="token punctuation">.</span>param_groups<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token string">'lr'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>      plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>     ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>arr2loss<span class="token punctuation">,</span> <span class="token string">'b-.'</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'loss'</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'epoch/100'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'loss'</span><span class="token punctuation">,</span> fontsize<span class="token operator">=</span><span class="token number">14</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>fontsize<span class="token operator">=</span><span class="token number">18</span><span class="token punctuation">)</span>     ax<span class="token punctuation">.</span>set_yscale<span class="token punctuation">(</span><span class="token string">'log'</span><span class="token punctuation">)</span>     plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>      <span class="token comment"># plt.cla()</span>     <span class="token comment"># plt.plot(x[:, 0], x[:, 1], y, 'b*')</span>     <span class="token comment"># plt.show()</span>   <span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>     test_DNN<span class="token punctuation">(</span><span class="token punctuation">)</span>  </code></pre> </p></div> 			                <div class="clearfix"></div>
                <div class="col-md-12 mt-5">
                                        <p>上一个：<a href="/news/article-98281.htm">动物打疫苗前后要注意什么事项呢（动物接种疫苗前的准备）</a></p>
                                        <p>下一个：<a href="/news/article-98956.htm">SpringBoot如何整合spring-retry来实现接口请求重试</a></p>
                                    </div>
                            </div>
            <div class="col-md-4 w3l-services">
                <h3 class="title-big mb-sm-3 mb-3">热门文章</h3>
<div class="row w3l-achievements">
    <div class="col-lg-12 item">
        <div class="card">
            <div class="box-wrap">
                <h4><a href="/news/article-80073.htm">新手养猫入门必备攻略有哪些（新手养猫宝典）</a></h4>
                <p>摘要：       本篇文章给大家谈谈新手养猫入门必备攻略有哪些，以及新手养猫宝典对应的知识点，希望对各位有所帮助，不要忘了收藏本站喔。本文目录一览：1、新手养猫科普指南2、...        本篇</p>
            </div>
        </div>
    </div>
</div>
<div class="row w3l-achievements">
    <div class="col-lg-12 item">
        <div class="card">
            <div class="box-wrap">
                <h4><a href="/news/article-90829.htm">猫咪怎么除跳蚤（猫咪除跳蚤项圈有用吗）</a></h4>
                <p>摘要：       今天给各位分享猫咪怎么除跳蚤的知识，其中也会对猫咪除跳蚤项圈有用吗进行解释，如果能碰巧解决你现在面临的问题，别忘了关注本站，现在开始吧！本文目录一览：1、小猫猫身上总有跳蚤,洗完.</p>
            </div>
        </div>
    </div>
</div>
<div class="row w3l-achievements">
    <div class="col-lg-12 item">
        <div class="card">
            <div class="box-wrap">
                <h4><a href="/news/article-88623.htm">windows下安装redis_在线工具</a></h4>
                <p>一、安装redis 下载地址： https://github.com/MicrosoftArchive/redis/releases Redis 支持 32 位和 64 位。这个需要根据你系统平台的实</p>
            </div>
        </div>
    </div>
</div>
<div class="row w3l-achievements">
    <div class="col-lg-12 item">
        <div class="card">
            <div class="box-wrap">
                <h4><a href="/free-nodes/2025-3-10-free-high-speed-nodes.htm">3月10日更新20.2M/S，2025年最新高速V2ray/Shadowrocket/SSR/Clash订阅链接免费节点地址分享</a></h4>
                <p>这一次的节点更新覆盖了香港、日本、美国、韩国、欧洲、加拿大、新加坡等地区,最高速度可达20.2 M/S。只需复制下方的Clash/v2ray订阅链接,在客户端添加后即可正常使用。</p>
            </div>
        </div>
    </div>
</div>
<div class="row w3l-achievements">
    <div class="col-lg-12 item">
        <div class="card">
            <div class="box-wrap">
                <h4><a href="/news/article-73944.htm">长沙领养宠物猫在哪里领（长沙领养宠物猫在哪里领养）</a></h4>
                <p>摘要：       今天给各位分享长沙领养宠物猫在哪里领的知识，其中也会对长沙领养宠物猫在哪里领养进行解释，如果能碰巧解决你现在面临的问题，别忘了关注本站，现在开始吧！本文目录一览：1、在哪里可以领.</p>
            </div>
        </div>
    </div>
</div>
<div class="row w3l-achievements">
    <div class="col-lg-12 item">
        <div class="card">
            <div class="box-wrap">
                <h4><a href="/news/article-93048.htm">宠物品牌起名字大全（宠物品牌介绍）</a></h4>
                <p>摘要：       今天给各位分享宠物品牌起名字大全的知识，其中也会对宠物品牌介绍进行解释，如果能碰巧解决你现在面临的问题，别忘了关注本站，现在开始吧！本文目录一览：1、宠物店取什么名字好...   </p>
            </div>
        </div>
    </div>
</div>
<div class="row w3l-achievements">
    <div class="col-lg-12 item">
        <div class="card">
            <div class="box-wrap">
                <h4><a href="/news/article-98956.htm">SpringBoot如何整合spring-retry来实现接口请求重试</a></h4>
                <p>一、重试机制 由于网络不稳定或网络抖动经常会造成接口请求失败的情况，当我们再去尝试就成功了，这就是重试机制。 本文首发于Java潘老师个人博客：SpringBoot整合spring-retry组件实现</p>
            </div>
        </div>
    </div>
</div>
<div class="row w3l-achievements">
    <div class="col-lg-12 item">
        <div class="card">
            <div class="box-wrap">
                <h4><a href="/free-nodes/2025-3-31-node-share-links.htm">3月31日更新20.1M/S，2025年最新高速Shadowrocket/Clash/SSR/V2ray订阅链接免费节点地址分享</a></h4>
                <p>这一次的节点更新覆盖了美国、欧洲、新加坡、日本、韩国、香港、加拿大等地区,最高速度可达20.1 M/S。只需复制下方的Clash/v2ray订阅链接,在客户端添加后即可正常使用。</p>
            </div>
        </div>
    </div>
</div>
<div class="row w3l-achievements">
    <div class="col-lg-12 item">
        <div class="card">
            <div class="box-wrap">
                <h4><a href="/free-nodes/2025-4-3-shadowrocket-node.htm">4月3日更新22.1M/S，2025年最新高速V2ray/Clash/Shadowrocket/SSR订阅链接免费节点地址分享</a></h4>
                <p>这一次的节点更新覆盖了香港、韩国、新加坡、美国、欧洲、日本、加拿大等地区,最高速度可达22.1 M/S。只需复制下方的Clash/v2ray订阅链接,在客户端添加后即可正常使用。</p>
            </div>
        </div>
    </div>
</div>
<div class="row w3l-achievements">
    <div class="col-lg-12 item">
        <div class="card">
            <div class="box-wrap">
                <h4><a href="/news/article-98281.htm">动物打疫苗前后要注意什么事项呢（动物接种疫苗前的准备）</a></h4>
                <p>摘要：       今天给各位分享动物打疫苗前后要注意什么事项呢的知识，其中也会对动物接种疫苗前的准备进行解释，如果能碰巧解决你现在面临的问题，别忘了关注本站，现在开始吧！本文目录一览：1、狗狗打疫.</p>
            </div>
        </div>
    </div>
</div>

<h3 class="title-big mb-sm-3 mb-3">归纳</h3>
<div class="row w3l-achievements">
    <div class="col-lg-12 item">
        <div class="card">
            <div class="box-wrap">
                                <h4><span class="badge" style="float: right;">54</span> <a href="/date/2025-04/" title="2025-04 归档">2025-04</a></h4>
                                <h4><span class="badge" style="float: right;">85</span> <a href="/date/2025-03/" title="2025-03 归档">2025-03</a></h4>
                            </div>
        </div>
    </div>
</div>
            </div>
        </div>
    </div>
        <!-- Footer -->
    <section class="w3l-footer py-sm-5 py-4">
        <div class="container">
            <div class="footer-content">
                <div class="row">
                    <div class="col-lg-8 footer-left">
                                            <p>
                                                <a href="/">首页</a> |
                                                <a href="/free-nodes/">免费节点</a> |
                                                <a href="/paid-subscribe/">推荐机场</a> |
                                                <a href="/client.htm">客户端</a> |
                                                <a href="/news/">新闻资讯</a> |
                                                <a href="/about-us.htm">关于我们</a> |
                        <a href="/disclaimer.htm">免责申明</a> |
                        <a href="/privacy.htm">隐私申明</a> |
                        <a href="/sitemap.xml">网站地图</a>
                    </p>
                        <p class="m-0">Clash Node官网订阅站 版权所有</p>
                    </div>
                    <div class="col-lg-4 footer-right text-lg-right text-center mt-lg-0 mt-3">
                        <ul class="social m-0 p-0">
                            <li><a href="#facebook"><span class="fa fa-facebook-official"></span></a></li>
                            <li><a href="#linkedin"><span class="fa fa-linkedin-square"></span></a></li>
                            <li><a href="#instagram"><span class="fa fa-instagram"></span></a></li>
                            <li><a href="#twitter"><span class="fa fa-twitter"></span></a></li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <!-- move top -->
        <button onclick="topFunction()" id="movetop" title="Go to top">
            <span class="fa fa-angle-up"></span>
        </button>
        <script>
        // When the user scrolls down 20px from the top of the document, show the button
        window.onscroll = function() {
            scrollFunction()
        };

        function scrollFunction() {
            if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
                document.getElementById("movetop").style.display = "block";
            } else {
                document.getElementById("movetop").style.display = "none";
            }
        }

        // When the user clicks on the button, scroll to the top of the document
        function topFunction() {
            document.body.scrollTop = 0;
            document.documentElement.scrollTop = 0;
        }
        </script>
        <!-- /move top -->
    </section>
    <!-- //Footer -->
    <!-- all js scripts and files here -->
    <script src="/assets/website/js/frontend/clashnode/theme-change.js"></script><!-- theme switch js (light and dark)-->
    <script src="/assets/website/js/frontend/clashnode/jquery-3.5.1.min.js"></script><!-- default jQuery -->
    <!-- /typig-text-->
    <script>
    const typedTextSpan = document.querySelector(".typed-text");
    const cursorSpan = document.querySelector(".cursor");

    const textArray = ["UI/UX Designer", "Freelancer", "Web developer"];
    const typingDelay = 200;
    const erasingDelay = 10;
    const newTextDelay = 100; // Delay between current and next text
    let textArrayIndex = 0;
    let charIndex = 0;

    function type() {
        if (charIndex < textArray[textArrayIndex].length) {
            if (!cursorSpan.classList.contains("typing")) cursorSpan.classList.add("typing");
            typedTextSpan.textContent += textArray[textArrayIndex].charAt(charIndex);
            charIndex++;
            setTimeout(type, typingDelay);
        } else {
            cursorSpan.classList.remove("typing");
            setTimeout(erase, newTextDelay);
        }
    }

    function erase() {
        if (charIndex > 0) {
            // add class 'typing' if there's none
            if (!cursorSpan.classList.contains("typing")) {
                cursorSpan.classList.add("typing");
            }
            typedTextSpan.textContent = textArray[textArrayIndex].substring(0, 0);
            charIndex--;
            setTimeout(erase, erasingDelay);
        } else {
            cursorSpan.classList.remove("typing");
            textArrayIndex++;
            if (textArrayIndex >= textArray.length) textArrayIndex = 0;
            setTimeout(type, typingDelay);
        }
    }

    document.addEventListener("DOMContentLoaded", function() { // On DOM Load initiate the effect
        if (textArray.length) setTimeout(type, newTextDelay + 250);
    });
    </script>
    <!-- //typig-text-->
    <!-- services owlcarousel -->
    <script src="/assets/website/js/frontend/clashnode/owl.carousel.js"></script>
    <!-- script for services -->
    <script>
    $(document).ready(function() {
        $('.owl-two').owlCarousel({
            loop: true,
            margin: 30,
            nav: false,
            responsiveClass: true,
            autoplay: false,
            autoplayTimeout: 5000,
            autoplaySpeed: 1000,
            autoplayHoverPause: false,
            responsive: {
                0: {
                    items: 1,
                    nav: false
                },
                480: {
                    items: 1,
                    nav: false
                },
                700: {
                    items: 1,
                    nav: false
                },
                1090: {
                    items: 3,
                    nav: false
                }
            }
        })
    })
    </script>
    <!-- //script for services -->
    <!-- script for tesimonials carousel slider -->
    <script>
    $(document).ready(function() {
        $("#owl-demo1").owlCarousel({
            loop: true,
            margin: 20,
            nav: false,
            responsiveClass: true,
            responsive: {
                0: {
                    items: 1,
                    nav: false
                },
                736: {
                    items: 1,
                    nav: false
                },
                1000: {
                    items: 2,
                    nav: false,
                    loop: false
                }
            }
        })
    })
    </script>
    <!-- //script for tesimonials carousel slider -->
    <!-- video popup -->
    <script src="/assets/website/js/frontend/clashnode/jquery.magnific-popup.min.js"></script>
    <script>
    $(document).ready(function() {
        $('.popup-with-zoom-anim').magnificPopup({
            type: 'inline',

            fixedContentPos: false,
            fixedBgPos: true,

            overflowY: 'auto',

            closeBtnInside: true,
            preloader: false,

            midClick: true,
            removalDelay: 300,
            mainClass: 'my-mfp-zoom-in'
        });

        $('.popup-with-move-anim').magnificPopup({
            type: 'inline',

            fixedContentPos: false,
            fixedBgPos: true,

            overflowY: 'auto',

            closeBtnInside: true,
            preloader: false,

            midClick: true,
            removalDelay: 300,
            mainClass: 'my-mfp-slide-bottom'
        });
    });
    </script>
    <!-- //video popup -->
    <!-- stats number counter-->
    <script src="/assets/website/js/frontend/clashnode/jquery.waypoints.min.js"></script>
    <script src="/assets/website/js/frontend/clashnode/jquery.countup.js"></script>
    <script>
    $('.counter').countUp();
    </script>
    <!-- //stats number counter -->
    <!-- disable body scroll which navbar is in active -->
    <script>
    $(function() {
        $('.navbar-toggler').click(function() {
            $('body').toggleClass('noscroll');
        })
    });
    </script>
    <!-- disable body scroll which navbar is in active -->
    <!--/MENU-JS-->
    <script>
    $(window).on("scroll", function() {
        var scroll = $(window).scrollTop();

        if (scroll >= 80) {
            $("#site-header").addClass("nav-fixed");
        } else {
            $("#site-header").removeClass("nav-fixed");
        }
    });

    //Main navigation Active Class Add Remove
    $(".navbar-toggler").on("click", function() {
        $("header").toggleClass("active");
    });
    $(document).on("ready", function() {
        if ($(window).width() > 991) {
            $("header").removeClass("active");
        }
        $(window).on("resize", function() {
            if ($(window).width() > 991) {
                $("header").removeClass("active");
            }
        });
    });
    </script>
    <!--//MENU-JS-->
    <!-- bootstrap js -->
    <script src="/assets/website/js/frontend/clashnode/bootstrap.min.js"></script>
    <script src="https://www.freeclashnode.com/assets/js/frontend/invite-url.js"></script><script src="/assets/website/js/frontend/G.js"></script>
</body>

</html>